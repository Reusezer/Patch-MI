#!/usr/bin/env python
"""bias_probe_fast_cli.py â€• top-K ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã ã‘ã‚’å› æœãƒ†ã‚¹ãƒˆã™ã‚‹é«˜é€Ÿãƒã‚¤ã‚¢ã‚¹è§£æ

ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã”ã¨ï¼‰
 1) ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã§ 1 å›æ¨è«–ã—ã€Î”â‚€ := logP(biased)âˆ’logP(anti) ã‚’å–å¾—ã€‚
 2) æŒ‡å®šå±¤ â„“ ã® MLP å‡ºåŠ›ã‹ã‚‰ |h| ã®å¹³å‡ãŒå¤§ãã„ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ä¸Šä½ K å€‹ã‚’å–å¾—ã€‚
 3) ãã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ i ã«å¯¾ã—ã¦ h_i â† +C ã¨ç½®æ›ã—å†æ¨è«– â†’ Î”_{â„“,i} ã€ã‚²ã‚¤ãƒ³ g_{â„“,i} = Î”_{â„“,i}âˆ’Î”â‚€ã€‚
 4) g_{â„“,i} æœ€å¤§ã®å±¤ã‚’ â˜… ã¨ã—ã¦ã‚«ã‚¦ãƒ³ãƒˆã€‚
---------------------------------------------------------------------------
å‡ºåŠ›
  bias_layer.csv         å±¤ â†’ star_count
  bias_neuron_stats.csv  (å±¤, ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³) â†’ hit_count & mean_gain
  
  CUDA_VISIBLE_DEVICES=0 \
python bias_probe_fast_cli.py \
  --bias_type race \
  --num_prompts 50 \
  --layers 5,10,15 \        # â† è§£æå±¤ã‚’çµã£ã¦ã•ã‚‰ã«é«˜é€ŸåŒ–
  --top_k 2 \               # å„å±¤ã§ä¸Šä½ 2 ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã ã‘ãƒ†ã‚¹ãƒˆ
  --C 10 \
  --report_top_layers 5 \
  --report_top_neurons 10 \
  --save_csv \
  --hf_token $HF_TOKEN
  
  
  --bias_type
CrowS-Pairs ã® bias_type åˆ—ï¼ˆrace, gender, religion â€¦ï¼‰ã§ãƒ‡ãƒ¼ã‚¿ã‚’çµã‚Šè¾¼ã¿ã¾ã™ã€‚æŒ‡å®šã—ãªã‘ã‚Œã°å…¨ã‚«ãƒ†ã‚´ãƒªã‚’å¯¾è±¡ã«ã—ã¾ã™ã€‚

--num_prompts
å‡¦ç†ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ•°ã‚’æ±ºã‚ã¾ã™ã€‚æ•´æ•°ã‚’æ¸¡ã›ã°ãã®ä»¶æ•°ã ã‘ã€all ã¨æ›¸ã‘ã°ãƒ•ã‚¡ã‚¤ãƒ«å…¨è¡Œã‚’ä½¿ã„ã¾ã™ã€‚æ—¢å®šã¯ 50 è¡Œã€‚

--layers
è§£æå¯¾è±¡ã®å±¤ã‚’æŒ‡å®šã—ã¾ã™ã€‚all ãªã‚‰ 0 ã‹ã‚‰æœ€çµ‚å±¤ã¾ã§å…¨éƒ¨ã€‚å˜ä¸€æ•°å­—ãªã‚‰ãã®å±¤ã ã‘ã€ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šãªã‚‰ä»»æ„ã®é›†åˆï¼ˆä¾‹ 1,3,7ï¼‰ã€‚çœç•¥ã—ã¦ã‚‚ all ã¨åŒç¾©ã§ã™ã€‚

--top_k
å„å±¤ã§ã€Œå¹³å‡çµ¶å¯¾æ´»æ€§ãŒå¤§ãã„ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã€ã‚’ä¸Šä½ K å€‹ã ã‘é¸ã³ã€å› æœãƒ†ã‚¹ãƒˆã—ã¾ã™ã€‚K ã‚’å¤§ããã™ã‚‹ã¨ç²¾åº¦ã¯ä¸ŠãŒã‚Šã¾ã™ãŒæ¨è«–å›æ•°ã‚‚å¢—ãˆã¾ã™ã€‚åˆæœŸå€¤ã¯ 1ã€‚

--C
å¼·åˆ¶ç™ºç«ã•ã›ã‚‹ã¨ãã«ãã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¸ä»£å…¥ã™ã‚‹å®šæ•°å€¤ã§ã™ã€‚æ´»æ€§ã‚’ +C ã«ç½®ãæ›ãˆãŸçŠ¶æ…‹ã§å†æ¨è«–ã—ã€ãƒã‚¤ã‚¢ã‚¹å¢—å¹…åº¦ã‚’æ¸¬ã‚Šã¾ã™ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ 10.0ã€‚

--report_top_layers
å®Ÿè¡Œçµ‚äº†å¾Œã€ãƒã‚¤ã‚¢ã‚¹å¢—å¹…ãŒæœ€ã‚‚å¤šãè¦³æ¸¬ã•ã‚ŒãŸå±¤ï¼ˆâ˜…å±¤ï¼‰ã‚’ä½•ä½ã¾ã§è¡¨ç¤ºã™ã‚‹ã‹ã‚’æ±ºã‚ã¾ã™ã€‚æ¨™æº–å‡ºåŠ›ã«ã ã‘å½±éŸ¿ã—ã€CSV ã«ã¯ç„¡é–¢ä¿‚ã§ã™ã€‚

--report_top_neurons
åŒæ§˜ã«ã€Œå¢—å¹…åº¦ãŒå¤§ãã„ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã€ã‚’ä½•ä»¶ã¾ã§è¡¨ç¤ºã™ã‚‹ã‹ã®æŒ‡å®šã§ã™ã€‚ã“ã‚Œã‚‚ç”»é¢å‡ºåŠ›ç”¨ã€‚

--save_csv
ã“ã®ãƒ•ãƒ©ã‚°ã‚’ä»˜ã‘ã‚‹ã¨ bias_layer.csv ã¨ bias_neuron_stats.csv ã‚’ bias_probe_out/ ãƒ•ã‚©ãƒ«ãƒ€ã¸æ›¸ãå‡ºã—ã¾ã™ã€‚ä»˜ã‘ãªã‘ã‚Œã°ãƒ•ã‚¡ã‚¤ãƒ«ã¯ä½œã‚Šã¾ã›ã‚“ã€‚

--device
æ¨è«–ã«ä½¿ã†ãƒ‡ãƒã‚¤ã‚¹ã€‚cuda, cuda:1, cpu ãªã©ã‚’æŒ‡å®šã—ã¾ã™ã€‚æ—¢å®šå€¤ã¯ cudaã€‚GPU ãŒç„¡ã„ç’°å¢ƒã§ã¯ cpu ã«å¤‰ãˆã¦ãã ã•ã„ã€‚

--hf_token
HuggingFace Hub ã§ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’å¼•ãå‡ºã™å ´åˆã®ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ã€‚ç’°å¢ƒå¤‰æ•° HF_TOKEN ã«è¨­å®šã—ã¦ãŠã‘ã°çœç•¥å¯èƒ½ã§ã™ã€‚

--base_id
è§£æå¯¾è±¡ã¨ãªã‚‹ â€œBaseâ€ ãƒ¢ãƒ‡ãƒ«ã® HuggingFace IDã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ meta-llama/Meta-Llama-3-8B ã§ã™ãŒã€å¥½ããª LLM ã«å¤‰æ›´ã§ãã¾ã™ã€‚

--aligned_id
äº’æ›æ€§ã®ãŸã‚å—ã‘å–ã‚Šã¾ã™ãŒã€ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ã¯ä½¿ã„ã¾ã›ã‚“ï¼ˆç„¡è¦–ã•ã‚Œã¾ã™ï¼‰ã€‚

--crows_url
CrowS-Pairs ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ‘ã‚¹ã¾ãŸã¯ URL ã‚’ä¸Šæ›¸ã

"""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ imports â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
import argparse, collections, os, sys, warnings
from pathlib import Path
from typing import Dict, List, Sequence, Tuple

import torch, torch.nn.functional as F
import pandas as pd
from tqdm import tqdm
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig

torch.backends.cuda.matmul.allow_tf32 = True
torch.set_float32_matmul_precision("high")

# CrowS ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ URL
CROWS_URL = ("https://raw.githubusercontent.com/nyu-mll/crows-pairs/master/"
             "data/crows_pairs_anonymized.csv")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CLI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
def parse_layers(arg: str, n: int) -> Sequence[int] | str:
    if arg.lower() == "all":
        return list(range(n))
    idxs = sorted({int(x) for x in arg.split(",") if x})
    if any(i < 0 or i >= n for i in idxs):
        raise argparse.ArgumentTypeError(f"layer idx {idxs} out of range 0..{n-1}")
    return idxs

def cli() -> argparse.Namespace:
    P = argparse.ArgumentParser()
    P.add_argument("--bias_type", default=None)
    P.add_argument("--num_prompts", default="50")           # N or "all"
    P.add_argument("--layers", default="all")
    P.add_argument("--top_k", type=int, default=1)
    P.add_argument("--C", type=float, default=10.0)
    P.add_argument("--report_top_layers", type=int, default=10)
    P.add_argument("--report_top_neurons", type=int, default=10)
    P.add_argument("--save_csv", action="store_true")
    P.add_argument("--device", default="cuda")
    P.add_argument("--hf_token", default=os.getenv("HF_TOKEN"))
    P.add_argument("--base_id", default="meta-llama/Meta-Llama-3-8B")
    P.add_argument("--aligned_id")          # äº’æ›ã®ãŸã‚å—ã‘å–ã‚‹ãŒæœªä½¿ç”¨
    P.add_argument("--crows_url", default=CROWS_URL)
    return P.parse_args()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ util â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
@torch.no_grad()
def logprob(model, tok, text: str, device):
    T = tok(text, return_tensors="pt").to(device)
    logits = model(**T).logits[:, :-1]
    tgt = T.input_ids[:, 1:]
    ll = F.log_softmax(logits, -1).gather(2, tgt.unsqueeze(-1)).squeeze(-1)
    return ll.sum().item()

def bias_score(model, tok, pair, device):
    a, b = pair
    return logprob(model,tok,b,device) - logprob(model,tok,a,device)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ main scan â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
def scan(model, tok, prompts, layers, top_k, C, device):
    mlps = [model.model.layers[i].mlp for i in layers]
    H    = model.config.hidden_size
    layer_hits = collections.Counter()
    neuron_stats: Dict[Tuple[int,int], List[float]] = collections.defaultdict(list)
    act_cache: Dict[int, torch.Tensor] = {}      # â˜… å„å±¤ã®å‡ºåŠ›ã‚’è²¯ã‚ã‚‹è¾æ›¸

    dtype  = torch.bfloat16
    devtype= "cuda" if str(device).startswith("cuda") else "cpu"
    ac = lambda: torch.amp.autocast(device_type=devtype, dtype=dtype)

    for a,b in tqdm(prompts, unit="prompt"):
        with ac(): base = bias_score(model,tok,(a,b),device)
        best_l, best_gain = -1, -1e9

        # forward once to get activations
        toks = tok(b, return_tensors="pt").to(device)
        act_cache.clear()                         # â˜… æ¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ç©ºã«æˆ»ã™
        hooks = []
        for li, mlp in enumerate(mlps):
            def make_store(index):
                # forward å‡ºåŠ›ã‚’è¾æ›¸ã«ä¿å­˜ã™ã‚‹ã‚¯ãƒ­ãƒ¼ã‚¸ãƒ£
                return (lambda _, __, out,
                             cache=act_cache, idx=index:
                             cache.__setitem__(idx, out.detach()))
            hooks.append(mlp.register_forward_hook(make_store(li)))
        with torch.no_grad(), ac():
            _ = model(**toks)
        for h in hooks:
            h.remove()

        for li, mlp in enumerate(mlps):
            acts = act_cache[li]
            meanabs = acts[0].abs().mean(0)
            vals, idxs = torch.topk(meanabs, k=min(top_k, H))
            for n in idxs.tolist():
                # 2) ãã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã ã‘ +C
                def h(_,__,out,idx=n,val=C): out[...,idx].fill_(val); return out
                hook = mlp.register_forward_hook(h)
                with ac():
                    gain = bias_score(model,tok,(a,b),device) - base
                hook.remove()

                neuron_stats[(layers[li], n)].append(gain)
                if gain > best_gain:
                    best_gain, best_l = gain, layers[li]
        layer_hits[best_l] += 1
    return layer_hits, neuron_stats

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ main() â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
def main():
    args = cli()
    warnings.filterwarnings("ignore")

    # model
    cfg = BitsAndBytesConfig(load_in_4bit=True,
                             bnb_4bit_quant_type="nf4",
                             bnb_4bit_compute_dtype=torch.bfloat16)
    tok = AutoTokenizer.from_pretrained(args.base_id, token=args.hf_token)
    tok.pad_token = tok.eos_token
    model = AutoModelForCausalLM.from_pretrained(
        args.base_id, device_map="auto",
        torch_dtype=torch.bfloat16, quantization_config=cfg,
        token=args.hf_token).to(args.device).eval()

    # prompts
    df = pd.read_csv(args.crows_url)
    if args.bias_type: df = df[df["bias_type"]==args.bias_type]
    if args.num_prompts!="all": df = df.head(int(args.num_prompts))
    prompts = list(zip(df["sent_more"], df["sent_less"]))
    if not prompts: sys.exit("âŒ no prompts")

    layer_sel = parse_layers(args.layers, model.config.num_hidden_layers)
    layer_hist, neuron_map = scan(model, tok, prompts,
                                  layer_sel, args.top_k, args.C, args.device)

    # print summary
    print("\nâ˜… top layers â˜…")
    for l,c in layer_hist.most_common(args.report_top_layers):
        print(f"layer {l}: {c} prompts")

    print("\nâ˜… top neurons â˜…")
    top = sorted(neuron_map.items(), key=lambda kv: sum(kv[1])/len(kv[1]), reverse=True)
    for (l,n),g in top[:args.report_top_neurons]:
        print(f"layer {l}, neuron {n}: mean Î” {sum(g)/len(g):.3f} | hits {len(g)}")

    # CSV
    if args.save_csv:
        out = Path("bias_probe_out"); out.mkdir(exist_ok=True)
        pd.DataFrame(layer_hist.items(), columns=["layer","star_count"]).to_csv(out/"bias_layer.csv",index=False)
        pd.DataFrame(
            [{"layer":l,"neuron_idx":n,"hit_count":len(g),"mean_gain":sum(g)/len(g)}
             for (l,n),g in neuron_map.items()]
        ).to_csv(out/"bias_neuron_stats.csv",index=False)
        print(f"\nğŸ“ CSVs written to {out}/")

if __name__ == "__main__":
    main()
